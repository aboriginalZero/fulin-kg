### 文件系统概念

文件系统（File System，FS）是一个构建在硬盘（块设备）上的用于控制数据存取的软件系统。从 OS 层面，实现了线性存储空间与目录层级结构的转换，从用户层面，为用户提供了一个方便管理文件的方式。当用户向某个文件写入数据时，文件系统会将该请求转换为对磁盘的操作，包括分配磁盘空间、写入数据等，而对文件的读操作则转换为定位到磁盘的某个位置，从磁盘读取数据。

文件系统不仅可以构建在块设备上，甚至可以构建在一个普通文件上。因为磁盘是一个线性空间，文件也是。对文件系统而言，所有文件都是字节流，它并不关注文件的格式和内容。

[Ext2 源码](https://code.woboq.org/linux/linux/fs/ext2/)

#### Linux 文件系统架构

Linux IO 栈由上而下主要分为用户层、VFS层、文件系统层、缓存层、块设备层、磁盘驱动层、磁盘物理层。

![linux文件系统详解- chaser24 - 博客园](https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202205051056687.png)

* AP

* VFS 。所有文件系统的共性抽象集合，如 file、inode、dentry 等结构体，read、write、close 等 API，具体的文件系统需要实现这些接口。当用户调用操作系统提供的文件系统 API 时，通过软中断的方式调用内核 VFS 实现的这些接口。VFS 层为上层抽象统一的操作界面，在 IO 路径上切换不同的文件系统。

* FS。做了一层文件的虚拟空间到实际线性设备的映射。为上层提供一个文件的概念。

* Block Device Driver。屏蔽不同的硬件驱动以及 IO 调度策略的优化。尽可能收集批量 IO 聚合下发，让 IO 尽可能的顺序，合并 IO 请求减少 IO 次数等。

* Disk Driver。硬件驱动层，如 SCSI 层等，负责和磁盘硬件做转换。

#### 文件类型

* 常规文件
* 目录文件
* 符号链接文件
* 其他文件。FIFO 文件（命名管道），以队列形式传递数据；Socket 文件，用于跨网传递数据；字符设备文件如串行端口终端、控制台；块设备如各类磁盘；

#### Inode 结构

```c++
// linux/fs/ext2/ext2.h
struct ext2_inode {
	__le16	i_mode;						// 文件访问模式
	__le16	i_uid;						// Owner ID
   	__le16	i_gid;						// Group ID
	__le32	i_size;						// 文件大小
	__le32	i_atime, i_ctime, i_mtime;	// 访问、创建、修改时间
	__le16	i_links_count;				// 链接数
	__le32	i_blocks;					// 数据块数量
   	__le32	i_block[EXT2_N_BLOCKS];		// 数据块位置指针
	__le32	i_flags;					// 文件 flag
    __le32	i_file_acl;					// ACL 数据位置
	__le32	i_dir_acl;					// 目录 ACL 数据位置
    ...;
};

// linux/include/linux/fs.h
struct inode {
    const struct inode_operations	*i_op;	// inode 操作指针
    const struct file_operations	*i_fop; // 文件操作指针
    ...;
};
```

inode 记录了文件的元数据，包括数据块索引、文件模式、文件链接数、文件拥有者、文件大小、文件访问时间等，除此之外，最重要的是每个 inode 都会采用多级索引的方式记录一个文件对应的所有数据块号。Inode 存储在硬盘上，为了加速文件访问，通常在文件被访问时加载到内存（inode 缓存）。

可以把 inode 类比成页表，页表将虚拟地址转换到物理地址，inode 将文件内偏移量转换到磁盘空间地址。

#### 目录文件

```c++
struct ext2_dir_entry_2 {
    __le32	inode;		// inode ID
    __le16	rec_len;	// 目录项长度
    __u8	name_len;	// 文件名长度
    __u8	file_type;	// 文件类型
    char	name[];		// 文件名
}
```

虽然通过 inode 号可以找到对应的文件，但对于人类使用来说，记忆 inode 号不是一个方便的事，所以引入字符串形式的文件名，但文件名不是文件的元数据，所以需要维护一个从文件名字符串到 inode 号之间的映射。而这就是目录要做的事。

与常规文件记录用户数据不同，每个目录中保存的是一种特殊的结构——目录项（dentry），目录项中记录的是常规文件文件名及其对应 inode 号的映射关系。每个目录项内的结构包括 inode 号、目录项长度、文件名长度、文件名。目录的大小并不取决于目录中的文件大小，而是取决于目录中文件的数量以及文件名的长度。目录项存储在硬盘上，有对应的目录项缓存。

在 POSIX 中，每个目录中有两个特殊的目录项，其中保存的文件名分别为 '.' 和 '..'，对应的 inode 号分别为该目录本身和其父目录。当一个新的目录文件被创建时，其本身的链接数为 2（因为 '.' 目录），同时其父目录的链接数 + 1（因为 '..' 目录）

由于目录项是一个接一个地存放在文件的数据块中组成一个连续的字符序列，所以在目录中查找也只能从目录文件中存放的第一个目录项开始，依次比较目录项中存放的文件名，找到期望的文件名后，根据该目录项保存的 inode 号找到文件的 inode，从而在 inode 上进行各种操作。

#### 软链接

也叫符号链接，软链接既可以是一种操作，也可以是一种文件，通过软链接生成软链接文件，会生成新的目录项和新的 inode。

与常规文件记录用户数据，目录文件记录目录项不同，符号链接文件中记录的是一个表示文件路径的字符串。由于路径的长度一般不会太长，软链接的一个简单实现是将路径字符串直接保存在 inode 中，占据原本用于保存数据块指针的空间。

读取软链接文件只需要找到该文件的 inode，并返回其中保存的路径即可。如果要一个修改软链接文件的内容，一般需要先删除原文件，再使用新的路径创建一个名字相同的软链接文件。

#### 硬链接

因为文件名并不是文件的元数据，所以一个文件可以对应多个文件名，为了给同一份数据创建多个文件名，文件系统引入硬链接。硬链接是一种为常规文件创建另一个名字的操作，由于文件名是存放在目录项中的，所以会生成新的目录项，但不会生成新的 inode。

当用户创建一个硬链接时，文件系统并不会创建一个新的 inode，而是先找到目标文件的 inode，在文件链接数字段上 +1，并在新名字所在目录的父目录中增加一个指向目标文件 inode 的目录项。

由于硬链接的存在，一个 inode 可能会被多个目录项所指向。只有当 inode 的链接数为 0 时，indoe 及其索引的结构和数据可以被销毁，相应的存储空间可以被释放。

软链接与硬链接的比较：

* 软链接可以链接到不存在的、跨文件系统的、是目录文件的目标路径，有独立的 inode 结构，所以有自己的权限、创建时间等元数据。
* 硬链接只能链接到本文件系统内已经存在的常规文件，与目标文件共享一个 inode 结构，二者没有主次之分。

### 使用文件系统

#### 注册、格式化、挂载

1. 注册文件系统。在 OS 加载内核模块的时候完成文件系统的注册，主要包括两件事：一是初始化 inode 缓存，二是添加该文件系统的 mount() 函数；
2. 格式化文件系统。以 extX 为例，格式化操作将磁盘以块组为单位划分，并将每个块组分成超级块、数据块/inode 位图、inode 表、数据块；
3. 挂载文件系统。在用户态发起挂载如 mount -t xfs /dev/sdc /mnt/xfs_test，主要功能由 VFS 层完成操作，包括获取待挂载文件系统类型数据结构等，而在 FS 层主要是调用了其实现的 mount() 函数，它的作用是从存储介质读取超级块信息，并创建该文件系统根目录的 dentry 实例。有了 dentry 相当于找到了该文件系统根目录对应的 inode，从而可以使用该 inode 的函数指针访问已挂载文件系统的数据。

格式化相当于在块设备上创建一个文件系统，而挂载则是将该文件系统激活（在操作系统目录树呈现）的过程。

#### 读文件

```c++
char data[20];
fd = open('/a/b/c.txt', O_RDWR|O_CREATE);
read(fd, data, 20);
```

1. 进程调用库函数 open ，libc 将其转换成 SYS_open 系统调用，通过软中断向内核发起打开文件请求；

2. 在VFS 解析文件路径，以 '/' 为分隔符将文件路径划分为多个字段，并逐级查找每级目录/文件名对应的 dentry 和 inode，如果有缓存使用缓存，否则从磁盘中加载到内存。路径解析完会得到 c.txt 文件对应的 inode 号，但是会将文件描述符而不是 inode 号返回给程序；

    > 为了避免每次打开文件都要路径解析和权限、文件类型检查，文件系统多做了一层 fd 到 inode 的转换，VFS 为每个进程维护一个列表元素为文件描述结构的打开文件列表，每个文件描述结构记录一个打开文件的 inode、当前读写位置、打开模式等。

3. 进程调用库函数 read，libc 将其转换成 SYS_read 系统调用，通过软中断向内核发起读请求；

4. VFS 以 fd 为下标在该进程的已打开文件列表中找到该文件对应的文件描述结构，从中可以得知 fd 对应的目标文件 inode，在 inode 上记录有这个文件的所有数据块号，通过对文件当前读位置取模可以定位到在哪个缓存页上，如果没有对应缓存页，产生缺页异常，将该份数据对应的直接数据块或是一级/二级间接指针指向的数据块填入一个新页；

5. 由于在创建文件时就会为 inode 设置操作文件的函数指针，并且在打开文件时，fd 对应的 inode 中的 read 函数指针会赋值给该文件描述结构中的 f_op 成员，所以通过 ftable[fd]->f_ops->read_iter() 的方式调用 ext2_file_read_iter() 函数从开始页上执行读操作，将数据拷贝到 data 中。

#### 写文件

```c++
fd = open('/a/b/c.txt', O_RDWR|O_CREATE);
write(fd, "hello\n", 6);
```

1. 进程调用库函数 open ，libc 将其转换成 SYS_open 系统调用，通过软中断向内核发起打开文件请求；
2. 经过 VFS 解析得到该文件对应的文件描述符 fd；
3. 进程调用库函数 write，libc 将其转换成 SYS_write 系统调用，通过软中断向内核发起写请求；
4. VFS 通过 fd 对应的文件描述结构找到文件写位置的缓存页，通过 ftable[fd]->f_ops->write_iter() 的方式将 "hello" 拷贝到开始页，并将该页标记为脏页，之后由 fsync 或文件系统定期写回数据块。

### 文件系统分类

#### 本地文件系统

从呈现形式上看，就是一个目录树。常见的有 Ext4、Btrfs、ZFS 等

#### 伪文件系统

内存中的文件系统，以文件系统的形态实现用户与内核数据交互的接口。比如 iostat 就是通过访问 /proc/diskstats 文件获取信息的。常见的有 proc、sysfs、configfs

#### 网络文件系统

基于 TCP/IP 的文件系统，除了需要挂载，使用方式与本地文件系统一致。常见的有 NFS。

NAS，网络附加存储（Network Attached Storage），NAS 技术在网络中放置一个单独的带有文件管理系统的存储服务器，其通过 SCSI 接口电缆连接存储阵列。集群中其他应用服务器通过 NFS、FTP 等网络共享协议得到 NAS 服务器上文件级别的数据共享。

优点
- 易于安装、部署、管理，只需要在磁盘阵列机柜外增加一套 NAS 服务器
- 应用程序通过网络访问 NAS 服务器，不增加应用服务器本身的 IO 开销

缺点
- NAS 必须具有接入以太网的能力，也就是必须具备以太网卡
- 由于通过网络访问，受限于网络延时、数据网络传输时可能产生的安全问题
- 应用程序只能以文件方式访问存储，由 NAS 服务器上的文件系统把对文件的操作映射成对磁盘数据块的操作，相比块请求的设备性能差

#### 集群文件系统

构建在基于网络的 SAN 设备上，且在多个节点中共享 SAN 磁盘。多个节点可以同时为应用层提供文件系统服务。

SAN，存储区域网络（Storage Area Network），SAN 技术通过交换机连接存储阵列和服务器主机，形成一个专用的 SAN 存储网络。SAN 是一种网络，提供数据块级别的存储服务，由客户端自实现文件系统。

优点

- 由于是独立的存储网络，容易横向扩展
- SAN 网络与 LAN 业务网络互相隔离，存储数据流不会占用业务带宽
- 提供块存储的数据共享，提高了存储的性能和升级能力

缺点

* 实现较难，成本较高

#### 分布式文件系统

作为网络文件系统的延伸，关键点在于存储端可以灵活地横向扩展。常见的有 GFS、HDFS、GlusterFS、CephFS 等

### 文件系统关键技术

#### 磁盘空间布局

文件系统需要知道磁盘空间哪些被使用，哪些没有被使用。这样在用户层需要使用磁盘空间时，才方便从未使用的区域分配磁盘空间。

##### 基于固定功能区的 layout

典型如 Linux 的 ExtX，先将磁盘以块组为单位划分，再按以下功能划分成以下几个区域：

![图7 Ext4 文件系统](https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202204171624075.png)

以块组 0 为例，各个功能区的特点是：

* 引导块。在 fs 作为 root fs 使用，在机器加电启动时，BIOS 装载并执行引导块，它包含一个启动装载程序，用于从计算机安装的操作系统中选择一个启动，还负责继续启动过程。因此 Ext2 把这个区域预留出来，不作为文件系统管理的磁盘区域。
* 超级块。存储了文件系统级别的信息，如逻辑块大小数量、inode 数量、挂载点等，Ext2 对超级块备份以避免突然断电或系统崩溃等引发元数据损坏的场景。
* 块组描述符。以列表的形式包含所有块组的信息，如每个块组中的数据块/inode 位图的位置、数据块/inode 的剩余数量。
* 预留 GDT 块。顾名思义，预留的，一般没啥用
* 数据块/inode 位图。描述块组中每一块数据块/inode 是否被使用，对于 Ext2 默认 4KB 的块大小，可以管理 4996 x 8 个逻辑块，即 4096 x 8 x 4096 = 128 MB 的空间。
* inode 表。以列表的形式保存文件的元数据信息，如文件大小、扩展属性和创建/修改时间等。每一项就是一个 inode 节点，对于 Ext2 默认的 inode 大小是 128 Byte
* 数据块。以上几项都算是元数据，在数据块进行用户数据的存储。

##### 基于非固定功能区的 layout

基于固定功能区的 layout 磁盘空间布局职能清晰，便于手动进行丢失数据的恢复。但元数据功能区大小固定，在海量小文件场景下容易出现磁盘剩余空间充足但 inode 资源不足的情况。因此出现了基于非固定功能区的 layout，典型如 XFS 和 NTFS，也分元数据和数据，但二者的区域大小是随着文件系统对资源的需求而动态分配的。不像 ExtX 通过固定的位图区域管理磁盘空间，XFS 通过 B+ 树管理，并且它的分配组（ExtX 中块组的概念）最大容量可以达到 1TB。

##### 基于数据追加的 layout

前面两种 layout 对于已分配的逻辑块，当对应的文件数据改动时通过在该逻辑块原地修改的。在文件随机 IO 比较多的情况下，不太适合 SSD 设备。因此出现了基于数据追加的 layout，典型如 NILFS2，以追加写的方式将数据变更写到后面的剩余空间上，将随机写转化为顺序写。

#### 文件数据管理

文件系统需要建立目录/文件的逻辑块与磁盘的物理块之间的映射关系。这样在用户访问文件数据时，才能找到对应的物理块。

> 感觉各种系统中，数据管理方式，要么数组，要么链表，要么哈希表（位图法）

##### 基于数组

访问磁盘 1 次，读写速度快，但是会产生外部碎片且难以动态扩充。主要应用在光盘、磁带等存储介质的文件系统中，如 ISOFS。

##### 基于链表

访问磁盘 n 次，无外部碎片以及动态增长方便，但是只能顺序查找，效率低下，且存放指针信息需要花费内存或磁盘空间。

##### 基于索引——间接块

访问磁盘 n + 1 次，无外部碎片，支持随机快速访问，但是需要维护索引表的存储开销，且对于大文件来说无法将索引数据一次性加载到内存。

为此，Ext2 的索引实现方式是多级索引 + 链表。在 inode 中存储一个长度为 15 的索引数组，前 12 项直接索引，然后是 1/2/3 级间接索引，小文件直接查找，大文件多级索引查找。

##### 基于索引——Extent

使用间接块的缺点在于数据越多，需要的元数据也越多，这种方式在一次大量写入、基本不修改的场景如视频文件等并不划算。理论上来说基于数组管理最合适，但它的缺点是处理不好追加写操作。

综合两者优势，出现了基于索引——Extent 的文件数据管理方式。其中，每一个索引项记录的值不是一个数据块的地址，而是数据块的起始地址和长度。如果出现追加写，只要需要分配一个新的 Extent。通常 Extent 是通过 B+ 树的方式组织，叶子结点在 inode 初始化时为加载到内存中，非叶子节点则在磁盘上，按需加载到内存中。

#### 文件传输

在不引入其他硬件的情况下，从磁盘文件拷贝数据到内核缓存区需要 CPU 参与，而这将导致计算机在执行 IO 行为时计算能力也跟着降低。因此引入直接内存访问技术（DMA），使得计算机能够用 DMA 控制器代替 CPU ，从磁盘文件拷贝数据到内核缓冲区。通过 DMA 技术从磁盘读取文件的流程如下：

[<img src="https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202205051056081.webp" alt="img" style="zoom:50%;" />]()

1. 用户进程借助系统调用 read ，向 OS 发出 I/O 请求，OS 收到后占用 CPU 给 DMA 控制器下发指令，告诉它读取多少数据，放在内存的哪个位置之后，将 CPU 让给其他进程；
2. DMA 控制器向磁盘控制器下发指令，通知它从磁盘读数据到磁盘内部的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；
3. DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区（Page Cache）中，当 DMA 读取足够多的数据之后，向 CPU 发起中断信号；
4. CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回。

尽管有 DMA 技术，但如果传输文件使用的是 read(file, buf, len) 和 write(socket, buf, len) 系统调用，那么还是不可避免地使用到 CPU。从硬盘读取数据，通过网卡向外发送，需要进行 4 次上下文切换和 4 次数据拷贝，其中 2 次 DMA 完成发生在内存里的缓冲区和对应的硬件设备之间的数据拷贝，另外 2 次由 CPU 完成发生在内核态和用户态之间的数据拷贝。

[<img src="https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202205051056595.webp" alt="img" style="zoom:50%;" />]()

为了避免不必要的数据拷贝，在网卡支持 SG-DMA 技术的情况下，Linux 通过 sendfile(socket, file, offset, len) 来使用零拷贝。从磁盘拷贝数据到网卡的过程中，没有在用户态层面拷贝数据，所有的数据都是通过 DMA 来进行传输的，只需要 2 次上下文切换和 2 次数据拷贝。

[<img src="https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202205051057411.webp" alt="img" style="zoom:50%;" />]()

Kafka 和 Nginx 等已广泛利用零拷贝技术，但是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。Linux 为此提供另一个系统调用 mmap(addr, len, fd, offset) ，通过 mmap 将一个文件中一定区域的数据直接映射到进程的虚拟地址空间，并返回内存空间的地址。这样就可以通过修改这个内存内容来修改文件内容，不需要使用 read write 系统调用来避免内存拷贝和上下文切换的消耗。

<img src="https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202205051057448.png" alt="image-20220411121325625" style="zoom: 50%;" />

如果条件允许，也可以使用 read + spdk write，共 2 次上下文切换 + 3 次数据拷贝。不过跟 mmap 比起来哪个性能更好？

#### 权限控制

##### RWX 权限控制

Linux 最常用的权限管理就是 RWX-UGO 权限管理，也就是 ls -l 所显示的第一列。但这种权限控制只能包含文件所有者和其他人，而无法控制多个不同的具体人，因此 Linux 引入 ACL 权限控制，ACL 允许给任何用户/用户组设置任何文件/目录的访问权限，这样就可以形成网状的交叉访问关系。

文件 a.txt 本来属于 abori 用户，期望该文件被 root 用户组的 root 用户读写

```
setfacl -m root:root:rw a.txt
```

##### ACL 权限控制

ACL 在 OS 内部是通过文件的扩展属性实现的。当用户为文件添加一个 ACL 规则时，其实就是添加一个扩展属性。由于经过特殊标记，所以普通用户查询扩展属性时 ACL 的数据是可以被文件系统屏蔽的。

Linux 文件系统的扩展属性以“键值”对的形式在文件外存储，被划分成四种空间

1. system：用于实现利用扩展属性的内核功能，如访问控制列表 ACL
2. security：用于实现内核安全模块，如 SELinux
3. trusted：把受限信息存入用户空间
4. User：用户为文件/目录添加一些附加信息，如文件的 MIME、文件编码和字符集等信息

##### SELinux 权限管理

SELinux 是一个在内核中实现的强制存取控制（MAC）安全性机制。SELinux 与 RWX、ACL 最大的区别是基于访问者（应用程序）与资源的规则，而不是用户与资源的规则，因此安全性更高。

![img](https://gitee.com/aboriginalZero/blogimage3/raw/master/img/202204172311397.png)

当访问者访问被访问者（资源）时，需要调用内核的接口。以读取某个目录的文件为例，需要读取 read 接口。此时会经过 SELinux 内核的判断逻辑，该判断逻辑根据策略数据库的内容确定访问者是否有权访问被访问者，如果权利允许则放行，否则拒绝并记录审计日志。

#### 并发控制

通过文件系统的文件锁机制来保证同步与互斥。从大类上分文件锁分为两种：

* 劝告锁（Advisory Lock），通过该锁通知访问者当前该文件被其他进程访问，但不强制阻止访问。
* 强制锁（Mandatory Lock），通过该锁避免已经有进程对文件锁定的情况下，其他进程再次访问。

在使用模式上，以上两种都有共享锁和排他锁的两种实现。

在 Linux 中默认使用的是劝告锁，如果进程没有对锁状态进行询问而直接访问数据，则锁不会保护数据。

为了对某个特定文件施行强制性上锁，需要使用强制锁，需要满足如下 3 个条件：

* 挂载文件系统时要指定 mand 选项（mount -o mand）
* 必须关闭文件的组成员执行位（chmod g-x file）
* 必须打开文件的 SGID 位，这是文件/目录的一种特殊权限，用于用户临时获取组权限（chmod g+s file）

#### 其他技术

**缓存技术**

读缓存实现对磁盘数据的预读，写缓存是对磁盘数据的延迟写入。缓存替换两大基本策略 LRU LFU

**快照与克隆技术**

快照实现文件的可读备份，克隆实现文件的可写备份。

克隆的数据最终会与原始文件的数据完全隔离。

不论是快照还是克隆，都有两种实现方式，区别在于修改时动的时快照文件的指向（COW）还是原始数据（ROW）

* 写时拷贝（COW）

    当原始文件被修改时，需要将该位置的原始数据拷贝到新的位置，并且更新快照文件中的地址信息，通常会有一个位图记录保证数据只会拷贝一次。

* 写时重定向（ROW）

    当原始文件写数据时并不在原始位置写入数据，而是分配一个新的位置，更新文件逻辑地址和实际数据位置的对应关系。

    对文件系统而言，用得最多的是 ROW，打快照时拷贝 inode 就可以表示一个快照文件，当原始文件发生修改时，需要将数据写入新的位置，并将原始文件中的地址信息进行变更即可。

**日志技术**

**配额管理**

针对用户（组）或目录进行使用空间的限制，可以针对文件数量、子目录数量等实现配额管理。
